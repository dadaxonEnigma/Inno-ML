{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa896ed2-df8e-4026-ab24-acf376014b32",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchvision import datasets, transforms\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "import numpy as np\n",
    "from sklearn.metrics import f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db3f2b76-d32b-472f-8707-7bcf1052b96c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Проверяем количество доступных GPU\n",
    "gpu_count = torch.cuda.device_count()\n",
    "print(f\"Количество доступных GPU: {gpu_count}\")\n",
    "\n",
    "# Если GPU доступен, выводим информацию о первом устройстве\n",
    "if gpu_count > 0:\n",
    "    print(f\"Информация о GPU 0: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"Объём памяти GPU 0: {torch.cuda.get_device_properties(0).total_memory / 1e9} GB\")\n",
    "else:\n",
    "    print(\"GPU не доступен.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "feb346bb-9370-4f45-a5a8-d6c0c8b5d9fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Устанавливаем преобразования для тренировочных и тестовых данных\n",
    "transform = transforms.Compose([transforms.Resize((224, 224)), transforms.ToTensor()])\n",
    "\n",
    "# Загрузка тренировочного и тестового датасетов\n",
    "train_dataset = datasets.Flowers102(root='data', split='train', download=True, transform= transform)\n",
    "validation_dataset = datasets.Flowers102(root='data', split='val', download=True, transform= transform)\n",
    "test_dataset = datasets.Flowers102(root='data', split='test', download=True, transform= transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a356a7d6-8172-46d0-80b8-3c1b1fa3e2ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Train dataset size: {len(train_dataset)}\")\n",
    "print(f\"Validation dataset size: {len(validation_dataset)}\")\n",
    "print(f\"Test dataset size: {len(test_dataset)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f182de6-2365-45dc-8178-5dc154aae89a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set = test_dataset\n",
    "combined_train_set = torch.utils.data.ConcatDataset([train_dataset, validation_dataset])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc534a1d-a9f4-4870-9caf-e25048c7fa77",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(train_set))\n",
    "print(len(combined_train_set))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a72fa0bc-52d3-4fd1-8a9a-99d522239cd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "txt_file = open('flowers102_label_names.txt','r').read().splitlines()\n",
    "class_names = [x.replace('\"','').replace(\"'\", '') for x in txt_file]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c31a32e-08fe-4b48-a510-95139392acd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def imshow(img, mean, std):\n",
    "    # Декодируем изображение обратно с учетом нормализации\n",
    "    for c in range(img.shape[0]):  # Для каждого канала\n",
    "        img[c] = img[c] * std[c] + mean[c]  # Обратная нормализация для каждого канала\n",
    "\n",
    "    img = np.clip(img, 0, 1)  # Ограничиваем значения пикселей в пределах [0, 1]\n",
    "    plt.imshow(img.transpose((1, 2, 0)))  # Переход от (C, H, W) к (H, W, C)\n",
    "    plt.axis('off')  # Отключаем оси\n",
    "    plt.show()\n",
    "\n",
    "# Извлекаем изображение из набора данных\n",
    "img_tensor = train_set[0][0]  # Получаем первое изображение (и его метку)\n",
    "\n",
    "# Нормализационные параметры для обратной нормализации\n",
    "mean = np.array([0.485, 0.456, 0.406])\n",
    "std = np.array([0.229, 0.224, 0.225])\n",
    "\n",
    "# Визуализируем изображение\n",
    "imshow(img_tensor.numpy(), mean, std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc367c31-f07c-41fb-823d-bd073a356f1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axis = plt.subplots(nrows=2, ncols=5, figsize=(15, 5))\n",
    "\n",
    "# В цикле проходим по всем осям и отображаем случайные изображения\n",
    "for ax in axis.ravel():\n",
    "    # Генерируем случайный индекс\n",
    "    idx = np.random.randint(len(train_set))\n",
    "    \n",
    "    # Получаем изображение и метку\n",
    "    img_tensor, label = train_set[idx]\n",
    "    \n",
    "    # Обратная нормализация\n",
    "    img_tensor = img_tensor * np.array([0.229, 0.224, 0.225])[:, None, None] + np.array([0.485, 0.456, 0.406])[:, None, None]\n",
    "    \n",
    "    # Преобразуем тензор из (C, H, W) в (H, W, C)\n",
    "    img = img_tensor.permute(1, 2, 0).numpy()\n",
    "    \n",
    "    # Отображаем изображение\n",
    "    ax.imshow(np.clip(img, 0, 1))  # Ограничиваем значения пикселей в диапазоне [0, 1]\n",
    "    \n",
    "    # Название класса\n",
    "    ax.set_title(class_names[label], fontsize=14)\n",
    "    \n",
    "    # Отключаем оси\n",
    "    ax.axis('off')\n",
    "\n",
    "# Показать изображение\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e45a1683-2ca0-4930-a71b-98fb14bf4b5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = DataLoader(train_set, batch_size=30, shuffle=True, drop_last=True)\n",
    "val_loader = DataLoader(validation_dataset, batch_size=30, shuffle=False)\n",
    "test_dataloader = DataLoader(combined_train_set, batch_size=30, shuffle=False,drop_last=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd060d23-9163-4b1a-af58-f57621a9d61a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Пример получения одного батча из train_loader\n",
    "data_iter = iter(train_dataloader)\n",
    "images, labels = next(data_iter)\n",
    "print(images.shape, labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "469cbdc7-42cd-4733-9b71-bfb54c625a98",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN, self).__init__()\n",
    "        \n",
    "        # Слои свёрточной нейронной сети\n",
    "        self.conv1 = nn.Conv2d(in_channels=3, out_channels=32, kernel_size=3, stride=1, padding=1)  # Слой 1\n",
    "        self.pool1 = nn.MaxPool2d(kernel_size=2, stride=2)  # Слой 2\n",
    "\n",
    "        self.conv2 = nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, stride=1, padding=1)  # Слой 3\n",
    "        self.pool2 = nn.MaxPool2d(kernel_size=2, stride=2)  # Слой 4\n",
    "        \n",
    "        self.conv3 = nn.Conv2d(in_channels=64, out_channels=128, kernel_size=3, stride=1, padding=1)  # Слой 5\n",
    "        self.pool3 = nn.MaxPool2d(kernel_size=2, stride=2)  # Слой 6\n",
    "        \n",
    "        self.flatten = nn.Flatten()  # Слой 7\n",
    "        \n",
    "        self.fc1 = nn.Linear(in_features=128 * 28 * 28, out_features=512)  # Слой 8 (128 * 16 * 16 - размер после свёрток и пулингов)\n",
    "        \n",
    "        \n",
    "        self.fc2 = nn.Linear(in_features=512, out_features=102)  # Слой 9\n",
    "\n",
    "        self.dropout = nn.Dropout(p=0.5)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # Прямой проход через сеть\n",
    "        x = self.conv1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.pool1(x)\n",
    "\n",
    "        x = self.conv2(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.pool2(x)\n",
    "\n",
    "        x = self.conv3(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.pool3(x)\n",
    "\n",
    "        x = self.flatten(x)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.dropout(x)\n",
    "\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "# Пример создания модели\n",
    "model = CNN()\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bed8d01f-9e4b-4b1f-8cdb-0788df873884",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install torchinfo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b10bdc86-4c19-4749-a5b7-675a4e361434",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchinfo import summary\n",
    "summary(CNN(), input_size=(30,3, 224, 224))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80345591-a5ca-48ec-b5c6-e73de0802a92",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c70de057-d163-4ad0-a707-9425a437d4c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "from torch.utils.tensorboard import SummaryWriter "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "927db157-c2cd-41ab-9753-9ad35b611456",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Создаём модель\n",
    "model = CNN()\n",
    "\n",
    "# Убираем использование GPU (если доступен)\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model.to(device)\n",
    "\n",
    "# Оптимизатор\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)  # SGD с моментумом\n",
    "\n",
    "# Функция потерь для многоклассовой классификации\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Логирование с использованием TensorBoard\n",
    "writer = SummaryWriter(log_dir='runs/flower_classification')  # Создаём директорию для TensorBoard\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf59247f-66c9-4285-bf2d-7cae238df1a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_losses = []\n",
    "val_losses = []\n",
    "train_accuracies = []\n",
    "val_accuracies = []\n",
    "\n",
    "num_epochs = 10  # Количество эпо\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    \n",
    "    running_loss = 0.0\n",
    "    correct_preds = 0\n",
    "    total_preds = 0\n",
    "    \n",
    "    for inputs, labels in train_dataloader:  # train_loader — это твой DataLoader для тренировочных данных\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "        optimizer.zero_grad()  # Обнуляем градиенты\n",
    "\n",
    "        outputs = model(inputs)  # Прямой проход\n",
    "        loss = criterion(outputs, labels)  # Вычисляем потерю\n",
    "\n",
    "        loss.backward()  # Обратное распространение\n",
    "        optimizer.step()  # Шаг оптимизации\n",
    "\n",
    "        running_loss += loss.item() * inputs.size(0)  # Накопление потерь\n",
    "        _, predicted = torch.max(outputs, 1)  # Выбираем класс с максимальной вероятностью\n",
    "        correct_preds += (predicted == labels).sum().item()\n",
    "        total_preds += labels.size(0)\n",
    "\n",
    "    # Логирование потерь и точности в TensorBoard\n",
    "    epoch_loss = running_loss / len(train_dataloader.dataset)\n",
    "    epoch_accuracy = correct_preds / total_preds\n",
    "    train_losses.append(epoch_loss)\n",
    "    train_accuracies.append(epoch_accuracy)\n",
    "\n",
    "    writer.add_scalar('Training Loss', epoch_loss, epoch)\n",
    "    writer.add_scalar('Training Accuracy', epoch_accuracy, epoch)\n",
    "\n",
    "    print(f'Epoch {epoch+1}/{num_epochs}, Loss: {epoch_loss:.4f}, Accuracy: {epoch_accuracy:.4f}')\n",
    "\n",
    " # Шаг валидации\n",
    "    model.eval()  # Переключаем модель в режим оценки (выключаем Dropout и BatchNorm, если есть)\n",
    "    \n",
    "    val_loss = 0.0\n",
    "    correct_preds_val = 0\n",
    "    total_preds_val = 0\n",
    "\n",
    "    with torch.no_grad():  # Отключаем вычисление градиентов для валидации\n",
    "        for inputs, labels in val_loader:  # val_loader — это твой DataLoader для валидационных данных\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "            outputs = model(inputs)  # Прямой проход\n",
    "            loss = criterion(outputs, labels)  # Вычисляем потерю\n",
    "\n",
    "            val_loss += loss.item() * inputs.size(0)  # Накопление потерь\n",
    "            _, predicted = torch.max(outputs, 1)  # Выбираем класс с максимальной вероятностью\n",
    "            correct_preds_val += (predicted == labels).sum().item()\n",
    "            total_preds_val += labels.size(0)\n",
    "\n",
    "    # Логирование потерь и точности на валидации в TensorBoard\n",
    "    val_loss = val_loss / len(val_loader.dataset)\n",
    "    val_accuracy = correct_preds_val / total_preds_val\n",
    "    val_losses.append(val_loss)\n",
    "    val_accuracies.append(val_accuracy)\n",
    "    \n",
    "    writer.add_scalar('Validation Loss', val_loss, epoch)\n",
    "    writer.add_scalar('Validation Accuracy', val_accuracy, epoch)\n",
    "\n",
    "    print(f'Epoch {epoch+1}/{num_epochs}, Validation Loss: {val_loss:.4f}, Validation Accuracy: {val_accuracy:.4f}')\n",
    "\n",
    "# Закрытие TensorBoard writer после тренировки\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5e64730-cadc-404e-86a1-6ce833b7e99e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Визуализация потерь\n",
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "# Потери\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(range(1, num_epochs + 1), train_losses, label='Training Loss', color='blue', marker='o')\n",
    "plt.plot(range(1, num_epochs + 1), val_losses, label='Validation Loss', color='red', marker='x')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "\n",
    "# Точность\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(range(1, num_epochs + 1), train_accuracies, label='Training Accuracy', color='blue', marker='o')\n",
    "plt.plot(range(1, num_epochs + 1), val_accuracies, label='Validation Accuracy', color='red', marker='x')\n",
    "plt.title('Training and Validation Accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "\n",
    "# Отображаем графики\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (myenv)",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
