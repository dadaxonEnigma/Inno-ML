{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xqXoek6foX8O"
   },
   "source": [
    "# Lab 4: Recurrent neural networks basics\n",
    "```\n",
    "- [S25] Advanced Machine Learning, Innopolis University\n",
    "- Teaching Assistant: Gcinizwe Dlamini\n",
    "```\n",
    "<hr>\n",
    "\n",
    "\n",
    "```\n",
    "Lab Plan\n",
    "1. Recap (Basics)\n",
    "2. Recurrent neural networks different achitectures\n",
    "3. Application of RNN\n",
    "4. Self practice task\n",
    "```\n",
    "\n",
    "<hr>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nuT6Ysf0JvnN"
   },
   "source": [
    "## 1. Basics (Sequences and RNN)\n",
    "\n",
    "\n",
    "Each rectangle is a vector and arrows represent functions (e.g. matrix multiply). Input vectors are in red, output vectors are in blue and green vectors hold the RNN's state. The core reason that recurrent nets are more exciting is that they allow us to operate over sequences of vectors\n",
    "\n",
    "![](http://karpathy.github.io/assets/rnn/diags.jpeg)\n",
    "\n",
    "### Mode details on the RNN cell\n",
    "\n",
    "<!-- ![](https://github.com/bentrevett/pytorch-sentiment-analysis/blob/master/assets/sentiment7.png?raw=1) -->\n",
    "\n",
    "![](https://github.com/bentrevett/pytorch-sentiment-analysis/blob/experimental/assets/sentiment7.png?raw=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HWIBtt8fMsfZ"
   },
   "source": [
    "## 1.2 Simple RNN cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "Qv-heWe4qX18"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 4, 3])"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "simple_sequence = torch.Tensor([[0.3,1.9,4.5], [0.4,0.1,0.23], [0.7,0.91,0.43], [0.34,0.01,0.002]])\n",
    "simple_sequence = simple_sequence.unsqueeze(0)\n",
    "simple_sequence.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YKfVculSNJiJ"
   },
   "source": [
    "The `simple_sequence` variable represents a sequence of length 4, where each element (time-stamp) is represented by a feature vector of length 3.\n",
    "\n",
    "\n",
    "$$a^{(t)} = b + Wh^{(t-1)} + Ux^{(t)}$$\n",
    "$$h^{(t)} = tanh(a^{(t)})$$\n",
    "$$h_t = tanh(W_{ih}x_t + b_{ih} + W_{hh}h_{(t-1)} + b_{hh})$$\n",
    "\n",
    "where $h_t$ represents the hidden state at time $t$\n",
    "\n",
    "\n",
    "Lets see whats inside Pytorch and compare with our theory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "mrzdTT8wM_Jc"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('weight_ih_l0', tensor([[ 0.9805, -0.9531,  0.3402]])),\n",
       "             ('weight_hh_l0', tensor([[0.5527]])),\n",
       "             ('bias_ih_l0', tensor([-0.3233])),\n",
       "             ('bias_hh_l0', tensor([0.7690]))])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "simple_rnn_layer = nn.RNN(input_size=3, hidden_size=1, num_layers = 1, bias = True, batch_first=True)\n",
    "simple_rnn_layer.state_dict()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Plu-RqsTOJ0T"
   },
   "source": [
    "## 1.2 Feedfoward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "-Gr8Or0OOQjE"
   },
   "outputs": [],
   "source": [
    "output_all, output_last = simple_rnn_layer(simple_sequence)\n",
    "\n",
    "wih = simple_rnn_layer.weight_ih_l0.squeeze(0)\n",
    "whh = simple_rnn_layer.weight_hh_l0.squeeze(0)\n",
    "\n",
    "bih = simple_rnn_layer.bias_ih_l0\n",
    "bhh = simple_rnn_layer.bias_hh_l0\n",
    "\n",
    "x = simple_sequence[0][0] # The first input feature of the first sequence\n",
    "\n",
    "# Computing the hidden state for time = 1\n",
    "h1 = torch.tanh(torch.Tensor(torch.dot(x,wih) + bih  + torch.dot(whh,torch.Tensor([0.0])) + bhh))\n",
    "\n",
    "\n",
    "assert h1.item() == output_all[0][0].item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "1MzkPEZkxQmq"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0.4298],\n",
       "         [0.7850],\n",
       "         [0.6884],\n",
       "         [0.8180]]], grad_fn=<TransposeBackward1>)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_all"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DnidxDXaStGF"
   },
   "source": [
    "**Task** : Compute all the other hidden states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "zSZ5woQHNs1A"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.4298314154148102,\n",
       " 0.7850464582443237,\n",
       " 0.6883629560470581,\n",
       " 0.8179722428321838]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = []\n",
    "\n",
    "h_previous = torch.Tensor([0.0])\n",
    "\n",
    "for i in range(simple_sequence.shape[1]):\n",
    "  # TODO: Compute and print the hidden states using the given example\n",
    "    x = simple_sequence[0][i]  # Input vector\n",
    "    \n",
    "    h_t = torch.tanh(torch.dot(x, wih) + bih + torch.dot(whh, h_previous) + bhh)\n",
    "    \n",
    "    result.append(h_t.item())  # saving results\n",
    "    h_previous = h_t # update hidden layer\n",
    "\n",
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sdMScA2sh3_G"
   },
   "source": [
    "## 2.1  Bidirectional RNN\n",
    "The concept behind a bidirectional RNN is simple. As well as having an RNN processing the words in the sentence from the first to the last (a forward RNN), we have a second RNN processing the words in the sentence from the **last to the first** (a backward RNN). At time step $t$, the forward RNN is processing word $x_t$, and the backward RNN is processing word $x_{T-t+1}$.\n",
    "\n",
    "$$\\hat{y}=f(h_T^\\rightarrow, h_T^\\leftarrow)$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "myhNEVbSj9Be"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('weight_ih_l0', tensor([[-0.1223, -0.7003,  0.7123]])),\n",
       "             ('weight_hh_l0', tensor([[0.9007]])),\n",
       "             ('bias_ih_l0', tensor([0.2881])),\n",
       "             ('bias_hh_l0', tensor([-0.7138])),\n",
       "             ('weight_ih_l0_reverse', tensor([[0.9240, 0.6898, 0.8998]])),\n",
       "             ('weight_hh_l0_reverse', tensor([[0.9774]])),\n",
       "             ('bias_ih_l0_reverse', tensor([0.6255])),\n",
       "             ('bias_hh_l0_reverse', tensor([-0.5311]))])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bi_rnn_layer = nn.RNN(input_size=3, hidden_size=1, num_layers = 1, bidirectional=True, bias = True, batch_first=True)\n",
    "bi_rnn_layer.state_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "IXxxUGb8kO_j"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-0.7058]],\n",
       "\n",
       "        [[ 1.0000]]], grad_fn=<StackBackward0>)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_all, output_last = bi_rnn_layer(simple_sequence)\n",
    "output_last"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "3Vcyert5kajY"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.8880,  1.0000],\n",
       "         [ 0.3961,  0.9342],\n",
       "         [-0.4506,  0.9728],\n",
       "         [-0.7058,  0.3946]]], grad_fn=<TransposeBackward1>)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_all"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YVNys6DSkr0l"
   },
   "source": [
    "**Task** : Compute all the other hidden states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "GhD_67YMkpDY"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0.8880150318145752, 0.39461836218833923),\n",
       " (0.3961097002029419, 0.9727751016616821),\n",
       " (-0.4506370723247528, 0.93424391746521),\n",
       " (-0.7057655453681946, 0.9999966025352478)]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = []\n",
    "\n",
    "wih_fwd = bi_rnn_layer.weight_ih_l0.squeeze(0)\n",
    "whh_fwd = bi_rnn_layer.weight_hh_l0.squeeze(0)\n",
    "bih_fwd = bi_rnn_layer.bias_ih_l0\n",
    "bhh_fwd = bi_rnn_layer.bias_hh_l0\n",
    "\n",
    "wih_bwd = bi_rnn_layer.weight_ih_l0_reverse.squeeze(0)\n",
    "whh_bwd = bi_rnn_layer.weight_hh_l0_reverse.squeeze(0)\n",
    "bih_bwd = bi_rnn_layer.bias_ih_l0_reverse\n",
    "bhh_bwd = bi_rnn_layer.bias_hh_l0_reverse\n",
    "h_fwd = torch.Tensor([0.0])  \n",
    "h_bwd = torch.Tensor([0.0])\n",
    "\n",
    "for i in range(simple_sequence.shape[1]):\n",
    "  # TODO: Compute and print the hidden states using the given example\n",
    "    x_fwd = simple_sequence[0][i]  \n",
    "    x_bwd = simple_sequence[0][-i - 1]  \n",
    "\n",
    "    h_fwd = torch.tanh(torch.dot(x_fwd, wih_fwd) + bih_fwd + torch.dot(whh_fwd, h_fwd) + bhh_fwd)\n",
    "    h_bwd = torch.tanh(torch.dot(x_bwd, wih_bwd) + bih_bwd + torch.dot(whh_bwd, h_bwd) + bhh_bwd)\n",
    "\n",
    "    result.append((h_fwd.item(), h_bwd.item()))  \n",
    "\n",
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ecfzuohalD5V"
   },
   "source": [
    "## 2.2 Multi-layer / Stacked-layer RNN\n",
    "\n",
    "The idea is that we add additional RNNs on top of the initial standard RNN, where each RNN added is another *layer*. The hidden state output by the first (bottom) RNN at time-step $t$ will be the input to the RNN above it at time step $t$. The prediction is then made from the final hidden state of the final (highest) layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "oXCnUvILlb-h"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('weight_ih_l0', tensor([[ 0.3051, -0.3719, -0.9945]])),\n",
       "             ('weight_hh_l0', tensor([[-0.0343]])),\n",
       "             ('bias_ih_l0', tensor([0.4285])),\n",
       "             ('bias_hh_l0', tensor([-0.5050])),\n",
       "             ('weight_ih_l0_reverse', tensor([[-0.3493,  0.9412, -0.5624]])),\n",
       "             ('weight_hh_l0_reverse', tensor([[0.1537]])),\n",
       "             ('bias_ih_l0_reverse', tensor([-0.2837])),\n",
       "             ('bias_hh_l0_reverse', tensor([-0.6106])),\n",
       "             ('weight_ih_l1', tensor([[-0.0176,  0.2359]])),\n",
       "             ('weight_hh_l1', tensor([[0.1203]])),\n",
       "             ('bias_ih_l1', tensor([0.9325])),\n",
       "             ('bias_hh_l1', tensor([-0.6230])),\n",
       "             ('weight_ih_l1_reverse', tensor([[-0.3068, -0.3985]])),\n",
       "             ('weight_hh_l1_reverse', tensor([[-0.5722]])),\n",
       "             ('bias_ih_l1_reverse', tensor([0.6833])),\n",
       "             ('bias_hh_l1_reverse', tensor([0.5232]))])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "multi_rnn_layer = nn.RNN(input_size=3, hidden_size=1, num_layers = 2, bidirectional=True, bias = True, batch_first=True)\n",
    "multi_rnn_layer.state_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "id": "L9fmrOXwml4e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.0404]],\n",
       "\n",
       "        [[-0.9534]],\n",
       "\n",
       "        [[ 0.1514]],\n",
       "\n",
       "        [[ 0.8913]]], grad_fn=<StackBackward0>)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_all, output_last = multi_rnn_layer(simple_sequence)\n",
    "output_last"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "id": "kEkuvjkCmxcA"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0.1018, 0.8913],\n",
       "         [0.1308, 0.8127],\n",
       "         [0.1988, 0.7946],\n",
       "         [0.1514, 0.9049]]], grad_fn=<TransposeBackward1>)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_all"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bqaXW_NQ884x"
   },
   "source": [
    "## 3. Application (News classification)\n",
    "\n",
    "### 3.1 Dataset Description\n",
    "\n",
    "The AG News dataset consists of 120,000 training and 7,600 test news articles, categorized into four labels: `World`, `Sports`, `Business`, and `Science/Technology`. Each article is paired with its corresponding label, and the goal is to predict the correct category based on the content."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "id": "MtaLjyIw-PkX"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "streamlit 1.32.0 requires packaging<24,>=16.8, but you have packaging 24.1 which is incompatible.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting datasets\n",
      "  Downloading datasets-3.3.2-py3-none-any.whl.metadata (19 kB)\n",
      "Requirement already satisfied: filelock in e:\\anaconda\\lib\\site-packages (from datasets) (3.13.1)\n",
      "Requirement already satisfied: numpy>=1.17 in e:\\anaconda\\lib\\site-packages (from datasets) (1.26.4)\n",
      "Collecting pyarrow>=15.0.0 (from datasets)\n",
      "  Downloading pyarrow-19.0.1-cp312-cp312-win_amd64.whl.metadata (3.4 kB)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in e:\\anaconda\\lib\\site-packages (from datasets) (0.3.8)\n",
      "Requirement already satisfied: pandas in e:\\anaconda\\lib\\site-packages (from datasets) (2.2.2)\n",
      "Requirement already satisfied: requests>=2.32.2 in e:\\anaconda\\lib\\site-packages (from datasets) (2.32.2)\n",
      "Requirement already satisfied: tqdm>=4.66.3 in e:\\anaconda\\lib\\site-packages (from datasets) (4.66.4)\n",
      "Collecting xxhash (from datasets)\n",
      "  Downloading xxhash-3.5.0-cp312-cp312-win_amd64.whl.metadata (13 kB)\n",
      "Collecting multiprocess<0.70.17 (from datasets)\n",
      "  Downloading multiprocess-0.70.16-py312-none-any.whl.metadata (7.2 kB)\n",
      "Requirement already satisfied: fsspec<=2024.12.0,>=2023.1.0 in e:\\anaconda\\lib\\site-packages (from fsspec[http]<=2024.12.0,>=2023.1.0->datasets) (2024.3.1)\n",
      "Requirement already satisfied: aiohttp in e:\\anaconda\\lib\\site-packages (from datasets) (3.9.5)\n",
      "Collecting huggingface-hub>=0.24.0 (from datasets)\n",
      "  Downloading huggingface_hub-0.29.1-py3-none-any.whl.metadata (13 kB)\n",
      "Requirement already satisfied: packaging in c:\\users\\user\\appdata\\roaming\\python\\python312\\site-packages (from datasets) (24.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in e:\\anaconda\\lib\\site-packages (from datasets) (6.0.1)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in e:\\anaconda\\lib\\site-packages (from aiohttp->datasets) (1.2.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in e:\\anaconda\\lib\\site-packages (from aiohttp->datasets) (23.1.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in e:\\anaconda\\lib\\site-packages (from aiohttp->datasets) (1.4.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in e:\\anaconda\\lib\\site-packages (from aiohttp->datasets) (6.0.4)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in e:\\anaconda\\lib\\site-packages (from aiohttp->datasets) (1.9.3)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in e:\\anaconda\\lib\\site-packages (from huggingface-hub>=0.24.0->datasets) (4.11.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in e:\\anaconda\\lib\\site-packages (from requests>=2.32.2->datasets) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in e:\\anaconda\\lib\\site-packages (from requests>=2.32.2->datasets) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in e:\\anaconda\\lib\\site-packages (from requests>=2.32.2->datasets) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in e:\\anaconda\\lib\\site-packages (from requests>=2.32.2->datasets) (2024.8.30)\n",
      "Requirement already satisfied: colorama in c:\\users\\user\\appdata\\roaming\\python\\python312\\site-packages (from tqdm>=4.66.3->datasets) (0.4.6)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\user\\appdata\\roaming\\python\\python312\\site-packages (from pandas->datasets) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in e:\\anaconda\\lib\\site-packages (from pandas->datasets) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in e:\\anaconda\\lib\\site-packages (from pandas->datasets) (2023.3)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\user\\appdata\\roaming\\python\\python312\\site-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\n",
      "Downloading datasets-3.3.2-py3-none-any.whl (485 kB)\n",
      "   ---------------------------------------- 0.0/485.4 kB ? eta -:--:--\n",
      "   -- ------------------------------------- 30.7/485.4 kB 1.3 MB/s eta 0:00:01\n",
      "   ----- --------------------------------- 71.7/485.4 kB 975.2 kB/s eta 0:00:01\n",
      "   ---------------- ----------------------- 194.6/485.4 kB 1.7 MB/s eta 0:00:01\n",
      "   --------------------------- ------------ 337.9/485.4 kB 2.1 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 485.4/485.4 kB 2.5 MB/s eta 0:00:00\n",
      "Downloading huggingface_hub-0.29.1-py3-none-any.whl (468 kB)\n",
      "   ---------------------------------------- 0.0/468.0 kB ? eta -:--:--\n",
      "   --------------------------------------- 468.0/468.0 kB 14.8 MB/s eta 0:00:00\n",
      "Downloading multiprocess-0.70.16-py312-none-any.whl (146 kB)\n",
      "   ---------------------------------------- 0.0/146.7 kB ? eta -:--:--\n",
      "   ---------------------------------------- 146.7/146.7 kB 4.4 MB/s eta 0:00:00\n",
      "Downloading pyarrow-19.0.1-cp312-cp312-win_amd64.whl (25.3 MB)\n",
      "   ---------------------------------------- 0.0/25.3 MB ? eta -:--:--\n",
      "   - -------------------------------------- 0.9/25.3 MB 57.0 MB/s eta 0:00:01\n",
      "   -- ------------------------------------- 1.3/25.3 MB 27.5 MB/s eta 0:00:01\n",
      "   --- ------------------------------------ 2.3/25.3 MB 18.5 MB/s eta 0:00:02\n",
      "   ---- ----------------------------------- 3.2/25.3 MB 18.3 MB/s eta 0:00:02\n",
      "   ----- ---------------------------------- 3.4/25.3 MB 15.3 MB/s eta 0:00:02\n",
      "   ---------- ----------------------------- 6.3/25.3 MB 23.7 MB/s eta 0:00:01\n",
      "   ----------- ---------------------------- 7.4/25.3 MB 23.5 MB/s eta 0:00:01\n",
      "   ----------- ---------------------------- 7.4/25.3 MB 23.5 MB/s eta 0:00:01\n",
      "   ------------- -------------------------- 8.6/25.3 MB 21.9 MB/s eta 0:00:01\n",
      "   ----------------- ---------------------- 10.9/25.3 MB 23.4 MB/s eta 0:00:01\n",
      "   ------------------ --------------------- 11.9/25.3 MB 25.2 MB/s eta 0:00:01\n",
      "   -------------------- ------------------- 12.9/25.3 MB 24.2 MB/s eta 0:00:01\n",
      "   --------------------- ------------------ 13.9/25.3 MB 28.5 MB/s eta 0:00:01\n",
      "   ---------------------- ----------------- 14.0/25.3 MB 26.2 MB/s eta 0:00:01\n",
      "   ---------------------- ----------------- 14.2/25.3 MB 21.8 MB/s eta 0:00:01\n",
      "   ------------------------- -------------- 15.9/25.3 MB 20.5 MB/s eta 0:00:01\n",
      "   -------------------------- ------------- 16.5/25.3 MB 19.3 MB/s eta 0:00:01\n",
      "   --------------------------- ------------ 17.2/25.3 MB 19.2 MB/s eta 0:00:01\n",
      "   ---------------------------- ----------- 17.9/25.3 MB 21.1 MB/s eta 0:00:01\n",
      "   ----------------------------- ---------- 18.7/25.3 MB 19.3 MB/s eta 0:00:01\n",
      "   ------------------------------ --------- 19.4/25.3 MB 19.3 MB/s eta 0:00:01\n",
      "   ------------------------------- -------- 20.1/25.3 MB 17.7 MB/s eta 0:00:01\n",
      "   -------------------------------- ------- 20.8/25.3 MB 16.4 MB/s eta 0:00:01\n",
      "   --------------------------------- ------ 21.4/25.3 MB 16.4 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 22.1/25.3 MB 16.0 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 22.9/25.3 MB 15.6 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 23.6/25.3 MB 15.2 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 24.3/25.3 MB 16.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------  25.1/25.3 MB 16.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------  25.2/25.3 MB 15.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------  25.2/25.3 MB 15.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 25.3/25.3 MB 13.4 MB/s eta 0:00:00\n",
      "Downloading xxhash-3.5.0-cp312-cp312-win_amd64.whl (30 kB)\n",
      "Installing collected packages: xxhash, pyarrow, multiprocess, huggingface-hub, datasets\n",
      "  Attempting uninstall: pyarrow\n",
      "    Found existing installation: pyarrow 14.0.2\n",
      "    Uninstalling pyarrow-14.0.2:\n",
      "      Successfully uninstalled pyarrow-14.0.2\n",
      "Successfully installed datasets-3.3.2 huggingface-hub-0.29.1 multiprocess-0.70.16 pyarrow-19.0.1 xxhash-3.5.0\n"
     ]
    },
    {
     "ename": "ImportError",
     "evalue": "The pyarrow installation is not built with support for the Parquet file format (DLL load failed while importing _parquet: Не найдена указанная процедура.)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[35], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m get_ipython()\u001b[38;5;241m.\u001b[39msystem(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpip install datasets\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m----> 3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mdatasets\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m load_dataset\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mre\u001b[39;00m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mcollections\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Counter\n",
      "File \u001b[1;32mE:\\anaconda\\Lib\\site-packages\\datasets\\__init__.py:17\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Copyright 2020 The HuggingFace Datasets Authors and the TensorFlow Datasets Authors.\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# Licensed under the Apache License, Version 2.0 (the \"License\");\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[38;5;66;03m# See the License for the specific language governing permissions and\u001b[39;00m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;66;03m# limitations under the License.\u001b[39;00m\n\u001b[0;32m     15\u001b[0m __version__ \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m3.3.2\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m---> 17\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01marrow_dataset\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Dataset\n\u001b[0;32m     18\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01marrow_reader\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ReadInstruction\n\u001b[0;32m     19\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbuilder\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ArrowBasedBuilder, BuilderConfig, DatasetBuilder, GeneratorBasedBuilder\n",
      "File \u001b[1;32mE:\\anaconda\\Lib\\site-packages\\datasets\\arrow_dataset.py:78\u001b[0m\n\u001b[0;32m     75\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtqdm\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcontrib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mconcurrent\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m thread_map\n\u001b[0;32m     77\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m config\n\u001b[1;32m---> 78\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01marrow_reader\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ArrowReader\n\u001b[0;32m     79\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01marrow_writer\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ArrowWriter, OptimizedTypedSequence\n\u001b[0;32m     80\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata_files\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m sanitize_patterns\n",
      "File \u001b[1;32mE:\\anaconda\\Lib\\site-packages\\datasets\\arrow_reader.py:27\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtyping\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m TYPE_CHECKING, List, Optional, Union\n\u001b[0;32m     26\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpyarrow\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpa\u001b[39;00m\n\u001b[1;32m---> 27\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpyarrow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mparquet\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpq\u001b[39;00m\n\u001b[0;32m     28\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtqdm\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcontrib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mconcurrent\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m thread_map\n\u001b[0;32m     30\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdownload\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdownload_config\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m DownloadConfig  \u001b[38;5;66;03m# noqa: F401\u001b[39;00m\n",
      "File \u001b[1;32mE:\\anaconda\\Lib\\site-packages\\pyarrow\\parquet\\__init__.py:20\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Licensed to the Apache Software Foundation (ASF) under one\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;66;03m# or more contributor license agreements.  See the NOTICE file\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# distributed with this work for additional information\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     17\u001b[0m \n\u001b[0;32m     18\u001b[0m \u001b[38;5;66;03m# flake8: noqa\u001b[39;00m\n\u001b[1;32m---> 20\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n",
      "File \u001b[1;32mE:\\anaconda\\Lib\\site-packages\\pyarrow\\parquet\\core.py:35\u001b[0m\n\u001b[0;32m     33\u001b[0m     \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpyarrow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_parquet\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01m_parquet\u001b[39;00m\n\u001b[0;32m     34\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[1;32m---> 35\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m(\n\u001b[0;32m     36\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe pyarrow installation is not built with support \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     37\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfor the Parquet file format (\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mstr\u001b[39m(exc)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m)\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     38\u001b[0m     ) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     40\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpyarrow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_parquet\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (ParquetReader, Statistics,  \u001b[38;5;66;03m# noqa\u001b[39;00m\n\u001b[0;32m     41\u001b[0m                               FileMetaData, RowGroupMetaData,\n\u001b[0;32m     42\u001b[0m                               ColumnChunkMetaData,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     46\u001b[0m                               FileDecryptionProperties,\n\u001b[0;32m     47\u001b[0m                               SortingColumn)\n\u001b[0;32m     48\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpyarrow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfs\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (LocalFileSystem, FileSystem, FileType,\n\u001b[0;32m     49\u001b[0m                         _resolve_filesystem_and_path, _ensure_filesystem)\n",
      "\u001b[1;31mImportError\u001b[0m: The pyarrow installation is not built with support for the Parquet file format (DLL load failed while importing _parquet: Не найдена указанная процедура.)"
     ]
    }
   ],
   "source": [
    "!pip install datasets\n",
    "\n",
    "from datasets import load_dataset\n",
    "import re\n",
    "from collections import Counter\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch.optim as optim\n",
    "import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MWe_TuGgDefS"
   },
   "source": [
    "### 3.2 Get Dataset and preprocess\n",
    "\n",
    "Here are the steps:\n",
    "\n",
    "1. **Load the Dataset**: Use the `datasets` library to load the dataset (AG News).\n",
    "2. **Tokenize the Text**: Split the text into smaller units (e.g., words or subwords).\n",
    "3. **Create a Vocabulary**: Build a vocabulary based on the tokens from the training dataset.\n",
    "4. **Encode the Text**: Convert the text into numerical representations, applying padding or truncation to ensure consistent input length.\n",
    "5. **Organize Data into Batches**: Use a DataLoader to batch the data for efficient training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "id": "XKjn9LRk_aIA"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'load_dataset' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[37], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Load the AG News dataset\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m dataset \u001b[38;5;241m=\u001b[39m \u001b[43mload_dataset\u001b[49m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mag_news\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# Check the dataset structure (train, test, validation splits)\u001b[39;00m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28mprint\u001b[39m(dataset)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'load_dataset' is not defined"
     ]
    }
   ],
   "source": [
    "# Load the AG News dataset\n",
    "dataset = load_dataset(\"ag_news\")\n",
    "\n",
    "# Check the dataset structure (train, test, validation splits)\n",
    "print(dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FBOzn77sEmFB"
   },
   "source": [
    "### 3.3 Tokenize & Encode Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bUozXd_QIXh4"
   },
   "outputs": [],
   "source": [
    "# Custom tokenization function (basic whitespace and punctuation removal)\n",
    "def tokenize(text):\n",
    "    text = text.lower()\n",
    "    text = re.sub(r'[^\\w\\s]', '', text)  # Remove punctuation\n",
    "    return text.split()  # Tokenize by whitespace\n",
    "\n",
    "# Build vocabulary from the dataset\n",
    "def build_vocab(dataset, min_freq=5):\n",
    "    counter = Counter()\n",
    "    for example in dataset:\n",
    "        tokens = tokenize(example['text'])\n",
    "        counter.update(tokens)\n",
    "\n",
    "    # Create vocabulary dictionary (word -> index)\n",
    "    vocab = {'<unk>': 0, '<pad>': 1}  # Special tokens\n",
    "    idx = 2\n",
    "    for word, count in counter.items():\n",
    "        if count >= min_freq:\n",
    "            vocab[word] = idx\n",
    "            idx += 1\n",
    "\n",
    "    return vocab\n",
    "\n",
    "# Build vocabulary from the training set\n",
    "train_data = dataset['train']\n",
    "vocab = build_vocab(train_data)\n",
    "\n",
    "# Tokenize the dataset and encode into integer indices\n",
    "def encode_text(text, vocab):\n",
    "    tokens = tokenize(text)\n",
    "    return [vocab.get(token, vocab['<unk>']) for token in tokens]\n",
    "\n",
    "# Encoding the train and test dataset\n",
    "def encode_data(dataset, vocab):\n",
    "    encoded_data = []\n",
    "    for example in dataset:\n",
    "        input_ids = encode_text(example['text'], vocab)\n",
    "        label = example['label']\n",
    "        encoded_data.append({'input_ids': input_ids, 'label': label})\n",
    "    return encoded_data\n",
    "\n",
    "train_encoded = encode_data(dataset['train'], vocab)\n",
    "test_encoded = encode_data(dataset['test'], vocab)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UB-X1_6RLYh0"
   },
   "source": [
    "### 3.4 Creating Dataloaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Mf_wknLjEppW"
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "class AGNewsDataset(Dataset):\n",
    "    def __init__(self, data, vocab, max_len=256):\n",
    "        self.data = data\n",
    "        self.vocab = vocab\n",
    "        self.max_len = max_len\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        example = self.data[idx]\n",
    "        input_ids = example['input_ids']\n",
    "        label = example['label']\n",
    "\n",
    "        # Padding or truncating to max_len\n",
    "        input_ids = input_ids[:self.max_len]  # Truncate to max_len\n",
    "        padding_len = self.max_len - len(input_ids)\n",
    "        input_ids = input_ids + [self.vocab['<pad>']] * padding_len  # Pad with <pad> token\n",
    "\n",
    "        return torch.tensor(input_ids), torch.tensor(label)\n",
    "\n",
    "# Create PyTorch datasets for train and test\n",
    "train_dataset = AGNewsDataset(train_encoded, vocab)\n",
    "test_dataset = AGNewsDataset(test_encoded, vocab)\n",
    "\n",
    "# Create dataloaders\n",
    "BATCH_SIZE = 32\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TS_38bytjFD5"
   },
   "source": [
    "## 3.5 Define RNN model\n",
    "\n",
    "The steps for defining the Model:\n",
    "1. **Embedding Layer**: Create an embedding layer to convert token indices into dense vector representations.\n",
    "2. **RNN Layer**: Use an RNN (or LSTM/GRU) to process the sequence of embeddings and capture temporal dependencies in the data.\n",
    "3. **Fully Connected Layer**: Add a fully connected layer to output the class probabilities (for classification tasks).\n",
    "4. **Apply Dropout**: Implement dropout to prevent overfitting by randomly dropping units during training.\n",
    "5. **Forward Pass**: Define the forward pass, which processes input sequences through the embedding, RNN, and fully connected layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "iYiHfYBDGu4f"
   },
   "outputs": [],
   "source": [
    "class RNNModel(nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_dim, hidden_dim, output_dim, n_layers, dropout):\n",
    "        super(RNNModel, self).__init__()\n",
    "\n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
    "        self.rnn = nn.RNN(embedding_dim, hidden_dim, num_layers=n_layers, dropout=dropout, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_dim, output_dim)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, input_ids):\n",
    "        embedded = self.embedding(input_ids)\n",
    "        rnn_out, hidden = self.rnn(embedded)\n",
    "        hidden = hidden[-1, :, :]  # Use the last hidden state\n",
    "        output = self.fc(self.dropout(hidden))\n",
    "        return output\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6z6xvENjpsi5"
   },
   "source": [
    "### 3.6 Model training parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xUtLqyRqc_Kf"
   },
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# Initialize model, loss function, and optimizer\n",
    "embedding_dim = 100\n",
    "hidden_dim = 256\n",
    "output_dim = 4  # 4 classes in AG News dataset\n",
    "n_layers = 2\n",
    "dropout = 0.5\n",
    "learning_rate = 0.001\n",
    "\n",
    "model = RNNModel(len(vocab), embedding_dim, hidden_dim, output_dim, n_layers, dropout)\n",
    "model.to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()  # For multi-class classification\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "# Training loop\n",
    "def train_model():\n",
    "    num_epochs = 5\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        for input_ids, label in train_loader:\n",
    "            input_ids, label = input_ids.to(device), label.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            output = model(input_ids)\n",
    "            loss = criterion(output, label)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            running_loss += loss.item()\n",
    "\n",
    "        print(f'Epoch {epoch+1}, Loss: {running_loss/len(train_loader):.4f}')\n",
    "\n",
    "train_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WO2Jf6_5p9uZ"
   },
   "source": [
    "### 3.7 Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "94P_7M77etNz"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Evaluate the model\n",
    "def evaluate_model():\n",
    "    model.eval()\n",
    "    predictions, labels = [], []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for input_ids, label in test_loader:\n",
    "            input_ids, label = input_ids.to(device), label.to(device)\n",
    "            output = model(input_ids)\n",
    "            preds = torch.argmax(output, dim=1)\n",
    "            predictions.extend(preds.cpu().numpy())\n",
    "            labels.extend(label.cpu().numpy())\n",
    "\n",
    "    accuracy = accuracy_score(labels, predictions)\n",
    "    print(f'Accuracy: {accuracy:.4f}')\n",
    "\n",
    "evaluate_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KpiKTZW8thDw"
   },
   "source": [
    "## 4. Tasks\n",
    "\n",
    "```\n",
    "Task 1\n",
    "Implement and train a non-RNN neural network for news analysis using AG News dataset and the following architecture:\n",
    "- Embedding Layer -> 1D Convolution -> Flattening layer -> Fully connected layer -> output layer\n",
    "- For Flattening layer use : Max-pooling or Average-pooling\n",
    "- For Embedding layer use pre-trained word embeddings (i.e FastText, GloVe)\n",
    "```\n",
    "\n",
    "<hr>\n",
    "\n",
    "```\n",
    "Task 2\n",
    "Implement, train and test a RNN model for Part-of-speech tagging task with the following requirements:\n",
    "  - RNN should be bidirectional\n",
    "  - RNN should be Multi-layered\n",
    "  - RNN should be use Regularization (i.e Dropout)\n",
    "```\n",
    "\n",
    "**Task 2 Datasets**: [Train](https://www.dropbox.com/s/x9n6f9o9jl7pno8/train_pos.txt?dl=1), [Test](https://www.dropbox.com/s/v8nccvq7jewcl8s/test_pos.txt?dl=1)\n",
    "\n",
    "[**Pretrained Word Embeddings**](https://pytorch.org/text/stable/vocab.html#pretrained-word-embeddings)\n",
    "\n",
    "[**1D convolutions**](https://pytorch.org/docs/stable/generated/torch.nn.Conv1d.html)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "M9HIGRUiixKK"
   },
   "source": [
    "## Self Tasks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found existing installation: pyarrow 14.0.1\n",
      "Uninstalling pyarrow-14.0.1:\n",
      "  Successfully uninstalled pyarrow-14.0.1\n",
      "Found existing installation: datasets 3.3.2\n",
      "Uninstalling datasets-3.3.2:\n",
      "  Successfully uninstalled datasets-3.3.2\n",
      "Found existing installation: packaging 24.1\n",
      "Uninstalling packaging-24.1:\n",
      "  Successfully uninstalled packaging-24.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Failed to remove contents in a temporary directory 'E:\\anaconda\\Lib\\site-packages\\~yarrow'.\n",
      "You can safely remove it manually.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pyarrow\n",
      "  Using cached pyarrow-19.0.1-cp312-cp312-win_amd64.whl.metadata (3.4 kB)\n",
      "Collecting datasets\n",
      "  Using cached datasets-3.3.2-py3-none-any.whl.metadata (19 kB)\n",
      "Requirement already satisfied: packaging in e:\\anaconda\\lib\\site-packages (23.2)\n",
      "Requirement already satisfied: filelock in e:\\anaconda\\lib\\site-packages (from datasets) (3.13.1)\n",
      "Requirement already satisfied: numpy>=1.17 in e:\\anaconda\\lib\\site-packages (from datasets) (1.26.4)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in e:\\anaconda\\lib\\site-packages (from datasets) (0.3.8)\n",
      "Requirement already satisfied: pandas in e:\\anaconda\\lib\\site-packages (from datasets) (2.2.2)\n",
      "Requirement already satisfied: requests>=2.32.2 in e:\\anaconda\\lib\\site-packages (from datasets) (2.32.2)\n",
      "Requirement already satisfied: tqdm>=4.66.3 in e:\\anaconda\\lib\\site-packages (from datasets) (4.66.4)\n",
      "Requirement already satisfied: xxhash in e:\\anaconda\\lib\\site-packages (from datasets) (3.5.0)\n",
      "Requirement already satisfied: multiprocess<0.70.17 in e:\\anaconda\\lib\\site-packages (from datasets) (0.70.16)\n",
      "Requirement already satisfied: fsspec<=2024.12.0,>=2023.1.0 in e:\\anaconda\\lib\\site-packages (from fsspec[http]<=2024.12.0,>=2023.1.0->datasets) (2024.3.1)\n",
      "Requirement already satisfied: aiohttp in e:\\anaconda\\lib\\site-packages (from datasets) (3.9.5)\n",
      "Requirement already satisfied: huggingface-hub>=0.24.0 in e:\\anaconda\\lib\\site-packages (from datasets) (0.29.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in e:\\anaconda\\lib\\site-packages (from datasets) (6.0.1)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in e:\\anaconda\\lib\\site-packages (from aiohttp->datasets) (1.2.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in e:\\anaconda\\lib\\site-packages (from aiohttp->datasets) (23.1.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in e:\\anaconda\\lib\\site-packages (from aiohttp->datasets) (1.4.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in e:\\anaconda\\lib\\site-packages (from aiohttp->datasets) (6.0.4)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in e:\\anaconda\\lib\\site-packages (from aiohttp->datasets) (1.9.3)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in e:\\anaconda\\lib\\site-packages (from huggingface-hub>=0.24.0->datasets) (4.11.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in e:\\anaconda\\lib\\site-packages (from requests>=2.32.2->datasets) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in e:\\anaconda\\lib\\site-packages (from requests>=2.32.2->datasets) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in e:\\anaconda\\lib\\site-packages (from requests>=2.32.2->datasets) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in e:\\anaconda\\lib\\site-packages (from requests>=2.32.2->datasets) (2024.8.30)\n",
      "Requirement already satisfied: colorama in c:\\users\\user\\appdata\\roaming\\python\\python312\\site-packages (from tqdm>=4.66.3->datasets) (0.4.6)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\user\\appdata\\roaming\\python\\python312\\site-packages (from pandas->datasets) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in e:\\anaconda\\lib\\site-packages (from pandas->datasets) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in e:\\anaconda\\lib\\site-packages (from pandas->datasets) (2023.3)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\user\\appdata\\roaming\\python\\python312\\site-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\n",
      "Using cached pyarrow-19.0.1-cp312-cp312-win_amd64.whl (25.3 MB)\n",
      "Using cached datasets-3.3.2-py3-none-any.whl (485 kB)\n",
      "Installing collected packages: pyarrow, datasets\n",
      "Successfully installed datasets-3.3.2 pyarrow-19.0.1\n"
     ]
    }
   ],
   "source": [
    "!pip uninstall -y pyarrow datasets packaging\n",
    "!pip install pyarrow datasets packaging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting scipy\n",
      "  Downloading scipy-1.15.2-cp312-cp312-win_amd64.whl.metadata (60 kB)\n",
      "     ---------------------------------------- 0.0/60.8 kB ? eta -:--:--\n",
      "     ------------ ------------------------- 20.5/60.8 kB 320.0 kB/s eta 0:00:01\n",
      "     ------------------- ------------------ 30.7/60.8 kB 259.2 kB/s eta 0:00:01\n",
      "     -------------------------------- ----- 51.2/60.8 kB 327.7 kB/s eta 0:00:01\n",
      "     -------------------------------------- 60.8/60.8 kB 293.7 kB/s eta 0:00:00\n",
      "Requirement already satisfied: numpy<2.5,>=1.23.5 in e:\\anaconda\\lib\\site-packages (from scipy) (1.26.4)\n",
      "Downloading scipy-1.15.2-cp312-cp312-win_amd64.whl (40.9 MB)\n",
      "   ---------------------------------------- 0.0/40.9 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/40.9 MB 1.9 MB/s eta 0:00:22\n",
      "   ---------------------------------------- 0.1/40.9 MB 1.3 MB/s eta 0:00:32\n",
      "   ---------------------------------------- 0.2/40.9 MB 1.8 MB/s eta 0:00:23\n",
      "   ---------------------------------------- 0.5/40.9 MB 2.7 MB/s eta 0:00:15\n",
      "    --------------------------------------- 0.8/40.9 MB 3.7 MB/s eta 0:00:11\n",
      "   - -------------------------------------- 1.4/40.9 MB 5.4 MB/s eta 0:00:08\n",
      "   - -------------------------------------- 2.0/40.9 MB 6.4 MB/s eta 0:00:07\n",
      "   -- ------------------------------------- 2.7/40.9 MB 7.8 MB/s eta 0:00:05\n",
      "   -- ------------------------------------- 2.7/40.9 MB 7.8 MB/s eta 0:00:05\n",
      "   --- ------------------------------------ 3.9/40.9 MB 8.8 MB/s eta 0:00:05\n",
      "   ----- ---------------------------------- 5.2/40.9 MB 10.4 MB/s eta 0:00:04\n",
      "   ------ --------------------------------- 6.1/40.9 MB 11.2 MB/s eta 0:00:04\n",
      "   ------- -------------------------------- 7.5/40.9 MB 12.9 MB/s eta 0:00:03\n",
      "   -------- ------------------------------- 8.9/40.9 MB 13.9 MB/s eta 0:00:03\n",
      "   --------- ------------------------------ 9.3/40.9 MB 14.2 MB/s eta 0:00:03\n",
      "   --------- ------------------------------ 9.3/40.9 MB 14.2 MB/s eta 0:00:03\n",
      "   ----------- ---------------------------- 12.2/40.9 MB 21.9 MB/s eta 0:00:02\n",
      "   ------------ --------------------------- 12.6/40.9 MB 22.6 MB/s eta 0:00:02\n",
      "   ------------ --------------------------- 12.6/40.9 MB 22.6 MB/s eta 0:00:02\n",
      "   -------------- ------------------------- 14.8/40.9 MB 23.4 MB/s eta 0:00:02\n",
      "   --------------- ------------------------ 15.4/40.9 MB 21.8 MB/s eta 0:00:02\n",
      "   --------------- ------------------------ 16.1/40.9 MB 20.5 MB/s eta 0:00:02\n",
      "   ---------------- ----------------------- 16.8/40.9 MB 20.5 MB/s eta 0:00:02\n",
      "   ----------------- ---------------------- 17.4/40.9 MB 19.2 MB/s eta 0:00:02\n",
      "   ----------------- ---------------------- 18.2/40.9 MB 18.2 MB/s eta 0:00:02\n",
      "   ------------------ --------------------- 18.7/40.9 MB 17.2 MB/s eta 0:00:02\n",
      "   ------------------ --------------------- 18.8/40.9 MB 17.2 MB/s eta 0:00:02\n",
      "   ------------------ --------------------- 19.0/40.9 MB 15.6 MB/s eta 0:00:02\n",
      "   ------------------- -------------------- 19.5/40.9 MB 15.6 MB/s eta 0:00:02\n",
      "   -------------------- ------------------- 20.5/40.9 MB 16.4 MB/s eta 0:00:02\n",
      "   -------------------- ------------------- 20.5/40.9 MB 16.4 MB/s eta 0:00:02\n",
      "   -------------------- ------------------- 21.0/40.9 MB 14.6 MB/s eta 0:00:02\n",
      "   -------------------- ------------------- 21.5/40.9 MB 13.4 MB/s eta 0:00:02\n",
      "   --------------------- ------------------ 21.9/40.9 MB 13.1 MB/s eta 0:00:02\n",
      "   --------------------- ------------------ 21.9/40.9 MB 13.1 MB/s eta 0:00:02\n",
      "   ---------------------- ----------------- 22.6/40.9 MB 11.7 MB/s eta 0:00:02\n",
      "   ---------------------- ----------------- 22.9/40.9 MB 12.1 MB/s eta 0:00:02\n",
      "   ---------------------- ----------------- 23.1/40.9 MB 11.7 MB/s eta 0:00:02\n",
      "   ---------------------- ----------------- 23.3/40.9 MB 11.1 MB/s eta 0:00:02\n",
      "   ----------------------- ---------------- 23.6/40.9 MB 10.6 MB/s eta 0:00:02\n",
      "   ----------------------- ---------------- 23.8/40.9 MB 10.1 MB/s eta 0:00:02\n",
      "   ----------------------- ---------------- 24.0/40.9 MB 9.6 MB/s eta 0:00:02\n",
      "   ----------------------- ---------------- 24.2/40.9 MB 9.4 MB/s eta 0:00:02\n",
      "   ----------------------- ---------------- 24.5/40.9 MB 9.0 MB/s eta 0:00:02\n",
      "   ------------------------ --------------- 24.8/40.9 MB 8.7 MB/s eta 0:00:02\n",
      "   ------------------------ --------------- 25.0/40.9 MB 8.4 MB/s eta 0:00:02\n",
      "   ------------------------ --------------- 25.3/40.9 MB 8.2 MB/s eta 0:00:02\n",
      "   ------------------------ --------------- 25.5/40.9 MB 8.0 MB/s eta 0:00:02\n",
      "   ------------------------- -------------- 25.7/40.9 MB 7.8 MB/s eta 0:00:02\n",
      "   ------------------------- -------------- 26.0/40.9 MB 7.6 MB/s eta 0:00:02\n",
      "   ------------------------- -------------- 26.3/40.9 MB 7.5 MB/s eta 0:00:02\n",
      "   ------------------------- -------------- 26.5/40.9 MB 7.4 MB/s eta 0:00:02\n",
      "   -------------------------- ------------- 26.8/40.9 MB 7.3 MB/s eta 0:00:02\n",
      "   -------------------------- ------------- 27.0/40.9 MB 7.1 MB/s eta 0:00:02\n",
      "   -------------------------- ------------- 27.3/40.9 MB 7.0 MB/s eta 0:00:02\n",
      "   -------------------------- ------------- 27.5/40.9 MB 6.8 MB/s eta 0:00:02\n",
      "   --------------------------- ------------ 27.8/40.9 MB 6.7 MB/s eta 0:00:02\n",
      "   --------------------------- ------------ 28.0/40.9 MB 6.6 MB/s eta 0:00:02\n",
      "   --------------------------- ------------ 28.3/40.9 MB 6.5 MB/s eta 0:00:02\n",
      "   --------------------------- ------------ 28.5/40.9 MB 6.4 MB/s eta 0:00:02\n",
      "   ---------------------------- ----------- 28.7/40.9 MB 6.4 MB/s eta 0:00:02\n",
      "   ---------------------------- ----------- 29.0/40.9 MB 6.2 MB/s eta 0:00:02\n",
      "   ---------------------------- ----------- 29.2/40.9 MB 6.3 MB/s eta 0:00:02\n",
      "   ---------------------------- ----------- 29.4/40.9 MB 6.2 MB/s eta 0:00:02\n",
      "   ----------------------------- ---------- 29.7/40.9 MB 6.1 MB/s eta 0:00:02\n",
      "   ----------------------------- ---------- 30.0/40.9 MB 6.0 MB/s eta 0:00:02\n",
      "   ----------------------------- ---------- 30.3/40.9 MB 5.9 MB/s eta 0:00:02\n",
      "   ----------------------------- ---------- 30.5/40.9 MB 5.8 MB/s eta 0:00:02\n",
      "   ------------------------------ --------- 30.8/40.9 MB 5.7 MB/s eta 0:00:02\n",
      "   ------------------------------ --------- 31.0/40.9 MB 5.8 MB/s eta 0:00:02\n",
      "   ------------------------------ --------- 31.3/40.9 MB 5.7 MB/s eta 0:00:02\n",
      "   ------------------------------ --------- 31.6/40.9 MB 5.7 MB/s eta 0:00:02\n",
      "   ------------------------------- -------- 31.9/40.9 MB 5.6 MB/s eta 0:00:02\n",
      "   ------------------------------- -------- 32.1/40.9 MB 5.5 MB/s eta 0:00:02\n",
      "   ------------------------------- -------- 32.4/40.9 MB 5.6 MB/s eta 0:00:02\n",
      "   ------------------------------- -------- 32.7/40.9 MB 5.5 MB/s eta 0:00:02\n",
      "   -------------------------------- ------- 33.0/40.9 MB 5.5 MB/s eta 0:00:02\n",
      "   -------------------------------- ------- 33.2/40.9 MB 5.5 MB/s eta 0:00:02\n",
      "   -------------------------------- ------- 33.5/40.9 MB 5.5 MB/s eta 0:00:02\n",
      "   -------------------------------- ------- 33.8/40.9 MB 5.6 MB/s eta 0:00:02\n",
      "   --------------------------------- ------ 34.0/40.9 MB 5.6 MB/s eta 0:00:02\n",
      "   --------------------------------- ------ 34.3/40.9 MB 5.6 MB/s eta 0:00:02\n",
      "   --------------------------------- ------ 34.6/40.9 MB 5.6 MB/s eta 0:00:02\n",
      "   ---------------------------------- ----- 34.9/40.9 MB 5.6 MB/s eta 0:00:02\n",
      "   ---------------------------------- ----- 35.1/40.9 MB 5.6 MB/s eta 0:00:02\n",
      "   ---------------------------------- ----- 35.4/40.9 MB 5.6 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 35.7/40.9 MB 5.6 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 35.9/40.9 MB 5.6 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 36.1/40.9 MB 5.6 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 36.4/40.9 MB 5.6 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 36.7/40.9 MB 5.6 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 37.0/40.9 MB 5.6 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 37.2/40.9 MB 5.7 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 37.5/40.9 MB 5.6 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 37.8/40.9 MB 5.7 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 38.1/40.9 MB 5.7 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 38.3/40.9 MB 5.7 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 38.6/40.9 MB 5.8 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 38.8/40.9 MB 5.7 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 39.1/40.9 MB 5.7 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 39.4/40.9 MB 5.8 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 39.6/40.9 MB 5.7 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 39.8/40.9 MB 5.7 MB/s eta 0:00:01\n",
      "   ---------------------------------------  40.1/40.9 MB 5.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------  40.3/40.9 MB 5.7 MB/s eta 0:00:01\n",
      "   ---------------------------------------  40.3/40.9 MB 5.7 MB/s eta 0:00:01\n",
      "   ---------------------------------------  40.5/40.9 MB 5.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------  40.8/40.9 MB 5.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------  40.9/40.9 MB 5.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 40.9/40.9 MB 5.4 MB/s eta 0:00:00\n",
      "Installing collected packages: scipy\n",
      "Successfully installed scipy-1.15.2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "ydata-profiling 4.9.0 requires scipy<1.14,>=1.4.1, but you have scipy 1.15.2 which is incompatible.\n"
     ]
    }
   ],
   "source": [
    "!pip install scipy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['Confidence', 'in', 'the', 'pound', 'is', 'widely', 'expected', 'to', 'take', 'another', 'sharp', 'dive', 'if', 'trade', 'figures', 'for', 'September', ',', 'due', 'for', 'release', 'tomorrow', ',', 'fail', 'to', 'show', 'a', 'substantial', 'improvement', 'from', 'July', 'and', 'August', \"'s\", 'near-record', 'deficits', '.'], ['Chancellor', 'of', 'the', 'Exchequer', 'Nigel', 'Lawson', \"'s\", 'restated', 'commitment', 'to', 'a', 'firm', 'monetary', 'policy', 'has', 'helped', 'to', 'prevent', 'a', 'freefall', 'in', 'sterling', 'over', 'the', 'past', 'week', '.']]\n",
      "[['NN', 'IN', 'DT', 'NN', 'VBZ', 'RB', 'VBN', 'TO', 'VB', 'DT', 'JJ', 'NN', 'IN', 'NN', 'NNS', 'IN', 'NNP', ',', 'JJ', 'IN', 'NN', 'NN', ',', 'VB', 'TO', 'VB', 'DT', 'JJ', 'NN', 'IN', 'NNP', 'CC', 'NNP', 'POS', 'JJ', 'NNS', '.'], ['NNP', 'IN', 'DT', 'NNP', 'NNP', 'NNP', 'POS', 'VBN', 'NN', 'TO', 'DT', 'NN', 'JJ', 'NN', 'VBZ', 'VBN', 'TO', 'VB', 'DT', 'NN', 'IN', 'NN', 'IN', 'DT', 'JJ', 'NN', '.']]\n"
     ]
    }
   ],
   "source": [
    "def load_data(file_path):\n",
    "    sentences = []\n",
    "    labels = []\n",
    "    with open(file_path, \"r\", encoding=\"utf-8\") as f:\n",
    "        sentence = []\n",
    "        label = []\n",
    "        for line in f:\n",
    "            line = line.strip()\n",
    "            if not line:  # Если пустая строка — начало нового предложения\n",
    "                if sentence:\n",
    "                    sentences.append(sentence)\n",
    "                    labels.append(label)\n",
    "                    sentence = []\n",
    "                    label = []\n",
    "            else:\n",
    "                word, tag = line.split()\n",
    "                sentence.append(word)\n",
    "                label.append(tag)\n",
    "                \n",
    "        # Добавляем последнее предложение, если файл не заканчивается пустой строкой\n",
    "        if sentence:\n",
    "            sentences.append(sentence)\n",
    "            labels.append(label)\n",
    "    \n",
    "    return sentences, labels\n",
    "\n",
    "# Загружаем данные\n",
    "train_texts, train_labels = load_data(\"train_pos.txt\")\n",
    "test_texts, test_labels = load_data(\"test_pos.txt\")\n",
    "\n",
    "print(train_texts[:2])  \n",
    "print(train_labels[:2])  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2.  Load pre-trained GloVe embeddings (300-dimensional)\n",
    "def load_glove_embeddings(file_path, embedding_dim=300):\n",
    "    embeddings = {}\n",
    "    with open(file_path, 'r', encoding='utf-8') as f:\n",
    "        for line in f:\n",
    "            values = line.split()\n",
    "            word = values[0]\n",
    "            vector = np.asarray(values[1:], dtype='float32')\n",
    "            embeddings[word] = vector\n",
    "    return embeddings\n",
    "\n",
    "# Load GloVe embeddings (download and specify the path)\n",
    "glove_embeddings = load_glove_embeddings('glove.6B.300d.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Prepare the data (convert words to indices and labels to indices)\n",
    "def preprocess_data(texts, glove_embeddings, vocab_size=10000, embedding_dim=300):\n",
    "    word2idx = {'<PAD>': 0, '<UNK>': 1}  # Padding and unknown words\n",
    "    idx2word = {0: '<PAD>', 1: '<UNK>'}\n",
    "    embedding_matrix = np.zeros((vocab_size, embedding_dim))\n",
    "    idx = 2  # Start indexing from 2 (0 and 1 are reserved for <PAD> and <UNK>)\n",
    "\n",
    "     # Build word-to-index and index-to-word dictionaries and embedding matrix\n",
    "    for sentence in texts:\n",
    "        for word in sentence:\n",
    "            if word not in word2idx:\n",
    "                word2idx[word] = idx\n",
    "                idx2word[idx] = word\n",
    "                idx += 1\n",
    "            if word in glove_embeddings:\n",
    "                embedding_matrix[word2idx[word]] = glove_embeddings[word]\n",
    "            else:\n",
    "                embedding_matrix[word2idx[word]] = np.random.randn(embedding_dim)  # Random initialization for unknown words\n",
    "\n",
    "    return word2idx, idx2word, embedding_matrix\n",
    "\n",
    "# Preprocess the texts and labels\n",
    "word2idx, idx2word, embedding_matrix = preprocess_data(texts, glove_embeddings)\n",
    "\n",
    "# Convert POS tags to indices\n",
    "unique_tags = list(set(tag for sentence in labels for tag in sentence))\n",
    "tag2idx = {tag: idx for idx, tag in enumerate(unique_tags)}\n",
    "idx2tag = {idx: tag for tag, idx in tag2idx.items()}\n",
    "\n",
    "# def convert_labels(labels, tag2idx):\n",
    "#     return [[tag2idx[tag] for tag in sentence] for sentence in labels]\n",
    "\n",
    "# labels_idx = convert_labels(labels, tag2idx)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Convert text data into sequences of indices\n",
    "def text_to_sequence(texts, word2idx, max_length):\n",
    "    sequences = []\n",
    "    for sentence in texts:\n",
    "        seq = [word2idx.get(word, 1) for word in sentence]\n",
    "        seq = seq[:max_length] \n",
    "        seq += [0] * (max_length - len(seq))  \n",
    "        sequences.append(seq)\n",
    "    return np.array(sequences)\n",
    "\n",
    "max_length = max(len(sentence) for sentence in train_texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = torch.tensor(text_to_sequence(train_texts, word2idx, max_length), dtype=torch.long)\n",
    "y_train = torch.tensor([[tag2idx[tag] for tag in sentence] + [0] * (max_length - len(sentence)) for sentence in train_labels], dtype=torch.long)\n",
    "\n",
    "X_test = torch.tensor(text_to_sequence(test_texts, word2idx, max_length), dtype=torch.long)\n",
    "y_test = torch.tensor([[tag2idx[tag] for tag in sentence] + [0] * (max_length - len(sentence)) for sentence in test_labels], dtype=torch.long)\n",
    "\n",
    "train_data = TensorDataset(X_train, y_train)\n",
    "test_data = TensorDataset(X_test, y_test)\n",
    "\n",
    "train_loader = DataLoader(train_data, batch_size=32, shuffle=True)\n",
    "test_loader = DataLoader(test_data, batch_size=32, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. Define the RNN model (Bidirectional, Multi-layered, with Dropout and Convolutions)\n",
    "class POS_RNN(nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_dim, embedding_matrix, num_classes, hidden_dim=256, num_layers=2, dropout=0.5):\n",
    "        super(POS_RNN, self).__init__()\n",
    "        \n",
    "        # Embedding layer (pretrained GloVe embeddings)\n",
    "        self.embedding = nn.Embedding.from_pretrained(torch.tensor(embedding_matrix, dtype=torch.float32), freeze=False)\n",
    "        \n",
    "        # Bidirectional LSTM layer with dropout\n",
    "        self.rnn = nn.LSTM(embedding_dim, hidden_dim, num_layers, batch_first=True, bidirectional=True, dropout=dropout)\n",
    "        \n",
    "        # 1D Convolution layer (optional, used for feature extraction)\n",
    "        self.conv1 = nn.Conv1d(embedding_dim, 64, kernel_size=5, padding=2)  # Convolution layer\n",
    "        self.pool = nn.MaxPool1d(2)  # Max pooling\n",
    "        \n",
    "        # Fully connected layers for classification\n",
    "        self.fc1 = nn.Linear(hidden_dim * 2, 128)  # Bidirectional LSTM outputs hidden_dim * 2\n",
    "        self.fc2 = nn.Linear(128, num_classes)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.embedding(x)\n",
    "        x = x.permute(0, 2, 1)  # Prepare for convolution (batch, embedding_dim, sequence_length)\n",
    "        x = self.conv1(x)  # Apply 1D convolution\n",
    "        x = self.pool(x)  # Apply max pooling\n",
    "        x = x.permute(0, 2, 1)  # Prepare for LSTM (batch, sequence_length, hidden_dim * 2)\n",
    "        \n",
    "        # Pass through LSTM\n",
    "        rnn_out, _ = self.rnn(x)\n",
    "        \n",
    "        # We can take the output from the last time step\n",
    "        rnn_out = rnn_out[:, -1, :]  # Get the output from the last time step for classification\n",
    "        \n",
    "        # Fully connected layers for final classification\n",
    "        x = self.fc1(rnn_out)\n",
    "        x = self.fc2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6. Initialize and train the model\n",
    "model = POS_RNN(vocab_size=10000, embedding_dim=300, embedding_matrix=embedding_matrix, num_classes=len(tag2idx))\n",
    "\n",
    "criterion = nn.CrossEntropyLoss() # Loss function for classification\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001) # Optimizer\n",
    "\n",
    "num_epochs = 10\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        loss = criterion(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    \n",
    "    model.eval()\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    with torch.no_grad():\n",
    "        for data, target in test_loader:\n",
    "            output = model(data)\n",
    "            _, preds = torch.max(output, 1)\n",
    "            all_preds.extend(preds.numpy())\n",
    "            all_labels.extend(target.numpy())\n",
    "    \n",
    "    accuracy = accuracy_score(all_labels, all_preds)\n",
    "    print(f'Epoch {epoch+1}/{num_epochs}, Accuracy: {accuracy:.4f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set model to evaluation mode\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    test_output = model(X_test)\n",
    "    _, test_preds = torch.max(test_output, 1)\n",
    "    print(\"Test Accuracy:\", accuracy_score(y_test, test_preds.numpy()))"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
